import os
from typing import TypedDict, Annotated, Sequence, Optional
from datetime import datetime
from enum import Enum
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.table import Table
from rich import print as rprint

from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint import MemorySaver
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage

from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# –í–∞—à YandexGPT –∞–¥–∞–ø—Ç–µ—Ä
from your_module import YandexGPT

# ==================== –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–û–°–¢–û–Ø–ù–ò–Ø ====================

class AgentState(TypedDict):
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ –≤ –≥—Ä–∞—Ñ–µ"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    query: str
    retrieved_docs: list
    needs_clarification: bool
    clarification_question: str
    search_performed: bool
    current_topic: str
    response: Optional[str]
    sources: list

# ==================== –ö–õ–ê–°–° –î–õ–Ø –†–ê–ë–û–¢–´ –° –ë–ê–ó–û–ô –ó–ù–ê–ù–ò–ô ====================

class KnowledgeBaseManager:
    def __init__(self, knowledge_base_path: str = "./knowledge_base"):
        self.knowledge_base_path = knowledge_base_path
        
        # –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π)
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        
        self.persist_directory = "./chroma_db"
        self.vectorstore = self._init_vectorstore()
    
    def _init_vectorstore(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        if os.path.exists(self.persist_directory) and os.listdir(self.persist_directory):
            return Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings
            )
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        console = Console()
        console.print("[yellow]–ò–Ω–¥–µ–∫—Å–∏—Ä—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π...[/yellow]")
        
        loader = DirectoryLoader(
            self.knowledge_base_path,
            glob="**/*.md",
            loader_cls=TextLoader,
            loader_kwargs={'encoding': 'utf-8'}
        )
        
        documents = loader.load()
        
        if not documents:
            console.print("[red]–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞![/red]")
            return Chroma.from_documents(
                documents=[],
                embedding=self.embeddings,
                persist_directory=self.persist_directory
            )
        
        # –£–º–Ω–æ–µ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=150,
            separators=["\n## ", "\n### ", "\n\n", "\n", " ", ""],
        )
        
        chunks = text_splitter.split_documents(documents)
        
        # –û–±–æ–≥–∞—â–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        for i, chunk in enumerate(chunks):
            source = chunk.metadata.get('source', 'unknown')
            relative_path = os.path.relpath(source, self.knowledge_base_path)
            category = os.path.dirname(relative_path)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            content = chunk.page_content
            first_line = content.split('\n')[0] if '\n' in content else content[:100]
            
            chunk.metadata.update({
                "chunk_id": f"{os.path.basename(source)}_chunk_{i}",
                "category": category,
                "indexed_date": datetime.now().isoformat(),
                "title": first_line[:200],
                "source_file": os.path.basename(source)
            })
        
        console.print(f"[green]–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤[/green]")
        
        return Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.persist_directory
        )
    
    def search(self, query: str, k: int = 4, filters: Optional[dict] = None) -> tuple[list, list]:
        """–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        if filters:
            retriever = self.vectorstore.as_retriever(
                search_kwargs={
                    "k": k,
                    "filter": filters
                }
            )
        else:
            retriever = self.vectorstore.as_retriever(search_kwargs={"k": k})
        
        docs = retriever.get_relevant_documents(query)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        contents = [doc.page_content for doc in docs]
        metadatas = [doc.metadata for doc in docs]
        
        return contents, metadatas
    
    def add_document(self, file_path: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ–µ)"""
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤—Å—ë
        self._init_vectorstore()

# ==================== –£–ó–õ–´ –ì–†–ê–§–ê ====================

class SysAdminAgent:
    def __init__(self):
        self.console = Console()
        self.kb_manager = KnowledgeBaseManager()
        self.llm = YandexGPT()
        
        # –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
        self.system_prompt = """–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞. 
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.
        
        –ü—Ä–∞–≤–∏–ª–∞:
        1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –ø–æ–ø—Ä–æ—Å–∏ —É—Ç–æ—á–Ω–∏—Ç—å –∏–ª–∏ —Å–∫–∞–∂–∏ —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å
        3. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π –æ—Ç–≤–µ—Ç –≤ markdown
        4. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω
        5. –ü—Ä–µ–¥–ª–∞–≥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∏ —Ä–µ—à–µ–Ω–∏—è"""
        
        self.clarification_prompt = """–¢—ã –¥–æ–ª–∂–µ–Ω –∑–∞–¥–∞—Ç—å —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
        –í–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø–æ–º–æ–≥–∞—é—â–∏–º —Å—É–∑–∏—Ç—å –ø–æ–∏—Å–∫.
        
        –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞: {query}
        
        –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ–¥–∏–Ω —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å."""
        
        self.router_prompt = """–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        –¢–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤:
        1. –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô_–í–û–ü–†–û–° - –≤–æ–ø—Ä–æ—Å –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ, —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π –∏ —Ç.–¥.
        2. –£–¢–û–ß–ù–ï–ù–ò–ï - –æ—Ç–≤–µ—Ç –Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        3. –ü–ï–†–ï–§–û–†–ú–£–õ–ò–†–û–í–ö–ê - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        4. –ù–û–í–ê–Ø_–¢–ï–ú–ê - —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å
        
        –ó–∞–ø—Ä–æ—Å: {query}
        
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ."""
    
    # ==================== –û–°–ù–û–í–ù–´–ï –£–ó–õ–´ ====================
    
    def route_query(self, state: AgentState) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä—É–µ—Ç"""
        query = state["query"]
        
        response = self.llm.ask(
            messages=[
                {"role": "system", "content": self.router_prompt.format(query=query)},
                {"role": "user", "content": query}
            ],
            max_tokens=50,
            temp=0.1
        )
        
        # –ß–∏—Å—Ç–∏–º –æ—Ç–≤–µ—Ç
        response = response.strip().upper()
        
        if "–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô_–í–û–ü–†–û–°" in response or "–ù–û–í–ê–Ø_–¢–ï–ú–ê" in response:
            return "search_knowledge_base"
        elif "–£–¢–û–ß–ù–ï–ù–ò–ï" in response:
            return "handle_clarification"
        elif "–ü–ï–†–ï–§–û–†–ú–£–õ–ò–†–û–í–ö–ê" in response:
            return "reformulate_and_search"
        else:
            return "search_knowledge_base"
    
    def search_knowledge_base(self, state: AgentState) -> dict:
        """–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        query = state["query"]
        
        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        category_filters = self._infer_category(query)
        
        # –ü–æ–∏—Å–∫
        contents, metadatas = self.kb_manager.search(
            query=query,
            k=4,
            filters=category_filters
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = self._format_context(contents, metadatas)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        needs_clarification = len(contents) == 0 or self._is_vague_context(contents)
        
        if needs_clarification:
            clarification = self._generate_clarification(query, contents)
            return {
                "retrieved_docs": contents,
                "needs_clarification": True,
                "clarification_question": clarification,
                "search_performed": True
            }
        else:
            return {
                "retrieved_docs": contents,
                "needs_clarification": False,
                "search_performed": True
            }
    
    def generate_response(self, state: AgentState) -> dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        query = state["query"]
        docs = state.get("retrieved_docs", [])
        
        if not docs or len(docs) == 0:
            response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
            
            # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–µ–π—Å—Ç–≤–∏–π
            response += "\n\n**–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**"
            response += "\n1. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å"
            response += "\n2. –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"
            response += "\n3. –ó–∞–¥–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å"
            
            return {
                "response": response,
                "sources": []
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        context = "\n\n".join([doc for doc in docs[:3]])  # –ë–µ—Ä–µ–º —Ç–æ–ø-3
        
        prompt = f"""{self.system_prompt}

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:
{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã—à–µ. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.
–í –∫–æ–Ω—Ü–µ —É–∫–∞–∂–∏, –Ω–∞ –∫–∞–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –æ—Å–Ω–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç."""

        response = self.llm.ask(
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temp=0.3
        )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∏—Ö –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è)
        sources = [f"–î–æ–∫—É–º–µ–Ω—Ç {i+1}" for i in range(min(3, len(docs)))]
        
        return {
            "response": response,
            "sources": sources
        }
    
    def ask_clarification(self, state: AgentState) -> dict:
        """–ó–∞–¥–∞–µ–º —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å"""
        clarification = state.get("clarification_question", 
                                "–ù–µ –º–æ–≥–ª–∏ –±—ã –≤—ã —É—Ç–æ—á–Ω–∏—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å?")
        
        return {
            "response": f"**–£—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å:** {clarification}\n\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å.",
            "needs_clarification": True
        }
    
    def handle_clarification_response(self, state: AgentState) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å"""
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º
        messages = state["messages"]
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏ –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        last_assistant_msg = None
        last_user_msg = None
        
        for msg in reversed(messages):
            if isinstance(msg, AIMessage) and last_assistant_msg is None:
                last_assistant_msg = msg.content
            elif isinstance(msg, HumanMessage) and last_user_msg is None:
                last_user_msg = msg.content
            
            if last_assistant_msg and last_user_msg:
                break
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        if last_assistant_msg and last_user_msg:
            improved_query = f"{state['query']} {last_user_msg}"
            return {"query": improved_query, "needs_clarification": False}
        
        return {"needs_clarification": False}
    
    # ==================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ ====================
    
    def _infer_category(self, query: str) -> Optional[dict]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
        query_lower = query.lower()
        
        category_map = {
            "linux": ["linux", "ubuntu", "debian", "centos", "bash", "ssh"],
            "windows": ["windows", "powershell", "active directory", "ad"],
            "network": ["—Å–µ—Ç—å", "network", "ip", "dns", "vpn", "firewall"],
            "docker": ["docker", "–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä", "container", "docker-compose"],
            "samba": ["samba", "–æ–±—â–∞—è –ø–∞–ø–∫–∞", "—Ä–∞—Å—à–∞—Ä–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞"]
        }
        
        for category, keywords in category_map.items():
            if any(keyword in query_lower for keyword in keywords):
                return {"category": category}
        
        return None
    
    def _format_context(self, contents: list, metadatas: list) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
        context_parts = []
        
        for i, (content, metadata) in enumerate(zip(contents, metadatas)):
            source = metadata.get('source_file', f'–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1}')
            title = metadata.get('title', '')
            
            context_parts.append(f"--- {source} ---")
            if title:
                context_parts.append(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
            context_parts.append(content)
            context_parts.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        
        return "\n".join(context_parts)
    
    def _is_vague_context(self, contents: list) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–º"""
        if not contents:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        total_length = sum(len(content) for content in contents)
        if total_length < 500:  # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        return False
    
    def _generate_clarification(self, query: str, docs: list) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å"""
        prompt = self.clarification_prompt.format(query=query)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        if docs:
            context_preview = "\n".join([doc[:200] + "..." for doc in docs[:2]])
            prompt += f"\n\n–ù–∞–π–¥–µ–Ω–∞ —Å–ª–µ–¥—É—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n{context_preview}"
        
        response = self.llm.ask(
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temp=0.3
        )
        
        return response.strip()

# ==================== –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ê ====================

def create_agent_graph() -> StateGraph:
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ –∞–≥–µ–Ω—Ç–∞"""
    
    agent = SysAdminAgent()
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ
    workflow = StateGraph(AgentState)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–∑–ª—ã
    workflow.add_node("route_query", agent.route_query)
    workflow.add_node("search_knowledge_base", agent.search_knowledge_base)
    workflow.add_node("generate_response", agent.generate_response)
    workflow.add_node("ask_clarification", agent.ask_clarification)
    workflow.add_node("handle_clarification_response", agent.handle_clarification_response)
    
    # –ù–∞—á–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞
    workflow.set_entry_point("route_query")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–µ—Ö–æ–¥—ã –∏–∑ route_query
    workflow.add_conditional_edges(
        "route_query",
        agent.route_query,  # –§—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —É–∑–ª–∞
        {
            "search_knowledge_base": "search_knowledge_base",
            "handle_clarification": "handle_clarification_response",
            "reformulate_and_search": "search_knowledge_base"
        }
    )
    
    # –ü–µ—Ä–µ—Ö–æ–¥—ã –∏–∑ search_knowledge_base
    def decide_after_search(state: AgentState) -> str:
        if state.get("needs_clarification", False):
            return "ask_clarification"
        else:
            return "generate_response"
    
    workflow.add_conditional_edges(
        "search_knowledge_base",
        decide_after_search,
        {
            "ask_clarification": "ask_clarification",
            "generate_response": "generate_response"
        }
    )
    
    # –ü–µ—Ä–µ—Ö–æ–¥—ã –∏–∑ handle_clarification_response
    workflow.add_edge("handle_clarification_response", "search_knowledge_base")
    
    # –ü–µ—Ä–µ—Ö–æ–¥—ã –∏–∑ ask_clarification
    workflow.add_edge("ask_clarification", END)
    
    # –ü–µ—Ä–µ—Ö–æ–¥—ã –∏–∑ generate_response
    workflow.add_edge("generate_response", END)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    memory = MemorySaver()
    
    # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –≥—Ä–∞—Ñ
    graph = workflow.compile(checkpointer=memory)
    
    return graph, agent

# ==================== –ò–ù–¢–ï–†–§–ï–ô–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ====================

class SysAdminAssistantCLI:
    def __init__(self):
        self.console = Console()
        self.graph, self.agent = create_agent_graph()
        self.current_thread = {"configurable": {"thread_id": "user_thread"}}
        
        self._print_welcome()
    
    def _print_welcome(self):
        """–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        welcome = Panel.fit(
            "[bold cyan]ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ (LangGraph)[/bold cyan]\n\n"
            "–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:\n"
            "‚Ä¢ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π\n"
            "‚Ä¢ –£—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n"
            "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–∏–∞–ª–æ–≥–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n"
            "‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤\n\n"
            "–ö–æ–º–∞–Ω–¥—ã:\n"
            "‚Ä¢ /stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "‚Ä¢ /add <—Ñ–∞–π–ª> - –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç\n"
            "‚Ä¢ /clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é\n"
            "‚Ä¢ /quit - –≤—ã—Ö–æ–¥",
            style="blue"
        )
        self.console.print(welcome)
    
    def process_query(self, query: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        initial_state: AgentState = {
            "messages": [HumanMessage(content=query)],
            "query": query,
            "retrieved_docs": [],
            "needs_clarification": False,
            "clarification_question": "",
            "search_performed": False,
            "current_topic": "",
            "response": None,
            "sources": []
        }
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≥—Ä–∞—Ñ
        try:
            result = self.graph.invoke(
                initial_state,
                config=self.current_thread
            )
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self._display_result(result)
            
        except Exception as e:
            self.console.print(f"[red]–û—à–∏–±–∫–∞: {e}[/red]")
    
    def _display_result(self, result: dict):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
        response = result.get("response", "")
        
        if not response:
            return
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∏–ª—å –ø–∞–Ω–µ–ª–∏
        if "–ò–∑–≤–∏–Ω–∏—Ç–µ" in response or "–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏" in response:
            style = "yellow"
            title = "‚ö†Ô∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        elif "–£—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å" in response:
            style = "cyan"
            title = "ü§î –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ"
        else:
            style = "green"
            title = "‚úÖ –û—Ç–≤–µ—Ç"
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ—Ç–≤–µ—Ç
        self.console.print(Panel(
            Markdown(response),
            title=title,
            style=style
        ))
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        sources = result.get("sources", [])
        if sources and "–£—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å" not in response:
            self._display_sources(sources)
        
        # –õ–æ–≥–∏—Ä—É–µ–º
        self._log_interaction(result)
    
    def _display_sources(self, sources: list):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        table = Table(title="üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏")
        table.add_column("‚Ññ", style="cyan")
        table.add_column("–¢–∏–ø", style="green")
        table.add_column("–û–ø–∏—Å–∞–Ω–∏–µ", style="white")
        
        for i, source in enumerate(sources, 1):
            table.add_row(str(i), "–î–æ–∫—É–º–µ–Ω—Ç", source)
        
        self.console.print(table)
    
    def _log_interaction(self, result: dict):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        log_file = "assistant_log.jsonl"
        
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": result.get("query", ""),
            "response_preview": result.get("response", "")[:500],
            "sources_count": len(result.get("sources", [])),
            "needed_clarification": result.get("needs_clarification", False)
        }
        
        import json
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
    
    def run_interactive(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"""
        while True:
            try:
                query = input("\nüîç –í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
                
                if not query:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–∞–Ω–¥—ã
                if query.lower() in ['/quit', '/exit', '/–≤—ã—Ö–æ–¥']:
                    self.console.print("[yellow]–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...[/yellow]")
                    break
                elif query.lower() == '/stats':
                    self._show_stats()
                    continue
                elif query.lower() == '/clear':
                    self._clear_history()
                    continue
                elif query.startswith('/add '):
                    self._add_document(query[5:].strip())
                    continue
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                self.process_query(query)
                
            except KeyboardInterrupt:
                self.console.print("\n[yellow]–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...[/yellow]")
                break
            except Exception as e:
                self.console.print(f"[red]–û—à–∏–±–∫–∞: {e}[/red]")
    
    def _show_stats(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–∑–∞–≥–ª—É—à–∫–∞)"""
        self.console.print("[cyan]–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ –±—É–¥—É—â–µ–º[/cyan]")
    
    def _clear_history(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞"""
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–¥
        import uuid
        self.current_thread = {"configurable": {"thread_id": f"thread_{uuid.uuid4()}"}}
        self.console.print("[green]–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞[/green]")
    
    def _add_document(self, file_path: str):
        """–î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        try:
            self.agent.kb_manager.add_document(file_path)
            self.console.print(f"[green]–î–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω: {file_path}[/green]")
        except Exception as e:
            self.console.print(f"[red]–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}[/red]")

# ==================== –ó–ê–ü–£–°–ö ====================

def main():
    assistant = SysAdminAssistantCLI()
    assistant.run_interactive()

if __name__ == "__main__":
    main()